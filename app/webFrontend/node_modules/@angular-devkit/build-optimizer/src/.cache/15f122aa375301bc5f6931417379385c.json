{"remainingRequest":"C:\\MyWorkSpace\\ВСУ Варна\\Дипломна работа\\geli\\app\\webFrontend\\node_modules\\@angular-devkit\\build-optimizer\\src\\build-optimizer\\webpack-loader.js??ref--8-1!C:\\MyWorkSpace\\ВСУ Варна\\Дипломна работа\\geli\\app\\webFrontend\\node_modules\\markdown-it\\lib\\parser_inline.js","dependencies":[{"path":"C:\\MyWorkSpace\\ВСУ Варна\\Дипломна работа\\geli\\app\\webFrontend\\node_modules\\markdown-it\\lib\\parser_inline.js","mtime":1455046404000},{"path":"C:\\MyWorkSpace\\ВСУ Варна\\Дипломна работа\\geli\\app\\webFrontend\\node_modules\\cache-loader\\dist\\cjs.js","mtime":1570090502498},{"path":"C:\\MyWorkSpace\\ВСУ Варна\\Дипломна работа\\geli\\app\\webFrontend\\node_modules\\@angular-devkit\\build-optimizer\\src\\build-optimizer\\webpack-loader.js","mtime":1528256844000}],"contextDependencies":[],"result":["/** internal\n * class ParserInline\n *\n * Tokenizes paragraph content.\n **/\n'use strict';\n\n\nvar Ruler           = require('./ruler');\n\n\n////////////////////////////////////////////////////////////////////////////////\n// Parser rules\n\nvar _rules = [\n  [ 'text',            require('./rules_inline/text') ],\n  [ 'newline',         require('./rules_inline/newline') ],\n  [ 'escape',          require('./rules_inline/escape') ],\n  [ 'backticks',       require('./rules_inline/backticks') ],\n  [ 'strikethrough',   require('./rules_inline/strikethrough').tokenize ],\n  [ 'emphasis',        require('./rules_inline/emphasis').tokenize ],\n  [ 'link',            require('./rules_inline/link') ],\n  [ 'image',           require('./rules_inline/image') ],\n  [ 'autolink',        require('./rules_inline/autolink') ],\n  [ 'html_inline',     require('./rules_inline/html_inline') ],\n  [ 'entity',          require('./rules_inline/entity') ]\n];\n\nvar _rules2 = [\n  [ 'balance_pairs',   require('./rules_inline/balance_pairs') ],\n  [ 'strikethrough',   require('./rules_inline/strikethrough').postProcess ],\n  [ 'emphasis',        require('./rules_inline/emphasis').postProcess ],\n  [ 'text_collapse',   require('./rules_inline/text_collapse') ]\n];\n\n\n/**\n * new ParserInline()\n **/\nfunction ParserInline() {\n  var i;\n\n  /**\n   * ParserInline#ruler -> Ruler\n   *\n   * [[Ruler]] instance. Keep configuration of inline rules.\n   **/\n  this.ruler = new Ruler();\n\n  for (i = 0; i < _rules.length; i++) {\n    this.ruler.push(_rules[i][0], _rules[i][1]);\n  }\n\n  /**\n   * ParserInline#ruler2 -> Ruler\n   *\n   * [[Ruler]] instance. Second ruler used for post-processing\n   * (e.g. in emphasis-like rules).\n   **/\n  this.ruler2 = new Ruler();\n\n  for (i = 0; i < _rules2.length; i++) {\n    this.ruler2.push(_rules2[i][0], _rules2[i][1]);\n  }\n}\n\n\n// Skip single token by running all rules in validation mode;\n// returns `true` if any rule reported success\n//\nParserInline.prototype.skipToken = function (state) {\n  var ok, i, pos = state.pos,\n      rules = this.ruler.getRules(''),\n      len = rules.length,\n      maxNesting = state.md.options.maxNesting,\n      cache = state.cache;\n\n\n  if (typeof cache[pos] !== 'undefined') {\n    state.pos = cache[pos];\n    return;\n  }\n\n  if (state.level < maxNesting) {\n    for (i = 0; i < len; i++) {\n      // Increment state.level and decrement it later to limit recursion.\n      // It's harmless to do here, because no tokens are created. But ideally,\n      // we'd need a separate private state variable for this purpose.\n      //\n      state.level++;\n      ok = rules[i](state, true);\n      state.level--;\n\n      if (ok) { break; }\n    }\n  } else {\n    // Too much nesting, just skip until the end of the paragraph.\n    //\n    // NOTE: this will cause links to behave incorrectly in the following case,\n    //       when an amount of `[` is exactly equal to `maxNesting + 1`:\n    //\n    //       [[[[[[[[[[[[[[[[[[[[[foo]()\n    //\n    // TODO: remove this workaround when CM standard will allow nested links\n    //       (we can replace it by preventing links from being parsed in\n    //       validation mode)\n    //\n    state.pos = state.posMax;\n  }\n\n  if (!ok) { state.pos++; }\n  cache[pos] = state.pos;\n};\n\n\n// Generate tokens for input range\n//\nParserInline.prototype.tokenize = function (state) {\n  var ok, i,\n      rules = this.ruler.getRules(''),\n      len = rules.length,\n      end = state.posMax,\n      maxNesting = state.md.options.maxNesting;\n\n  while (state.pos < end) {\n    // Try all possible rules.\n    // On success, rule should:\n    //\n    // - update `state.pos`\n    // - update `state.tokens`\n    // - return true\n\n    if (state.level < maxNesting) {\n      for (i = 0; i < len; i++) {\n        ok = rules[i](state, false);\n        if (ok) { break; }\n      }\n    }\n\n    if (ok) {\n      if (state.pos >= end) { break; }\n      continue;\n    }\n\n    state.pending += state.src[state.pos++];\n  }\n\n  if (state.pending) {\n    state.pushPending();\n  }\n};\n\n\n/**\n * ParserInline.parse(str, md, env, outTokens)\n *\n * Process input string and push inline tokens into `outTokens`\n **/\nParserInline.prototype.parse = function (str, md, env, outTokens) {\n  var i, rules, len;\n  var state = new this.State(str, md, env, outTokens);\n\n  this.tokenize(state);\n\n  rules = this.ruler2.getRules('');\n  len = rules.length;\n\n  for (i = 0; i < len; i++) {\n    rules[i](state);\n  }\n};\n\n\nParserInline.prototype.State = require('./rules_inline/state_inline');\n\n\nmodule.exports = ParserInline;\n",null]}